{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Story 1\n",
    "- User initializes several algorithm and dataset combinations\n",
    "- the respective objects are created and substeps of the experiment pipeline are executed subsequently.\n",
    "- Users algorithm choice is MR-Hydra, Weasel-V2 and QUANT (which are the best performing & most time efficient of their category). \n",
    "- Datasets involved are: ElectricDevices(10%) and LargeKitchenApplications\n",
    "- Sometimes the user is interested in visualizing the data before applying DCA. Some performance metrics are visualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import gridspec\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import time\n",
    "from tsml_eval.publications.y2023.tsc_bakeoff.run_experiments import _set_bakeoff_classifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-07 11:30:26] INFO - Custom-named logger active.\n",
      "[2025-05-07 11:30:26] INFO - Custom-named logger active.\n"
     ]
    }
   ],
   "source": [
    "from src.basic_func import dataset_provider,dataset_overview, overview_of_bakeoff_cl\n",
    "from src.apply_dca import apply_label_errors\n",
    "from src.visualizations import visualize_acc_decr, visualize_trace_M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"Beef\"                   #should be in DS_list\n",
    "CLASSIFIER_NAME = \"Quant\"            #should be in cl_ names\n",
    "REDUCTION_F = 1                         #optional. only for large datasets\n",
    "RANDOM_S = 0                            #Random Seed for everything except the DCA\n",
    "DCA= \"LabelErrors\"                      #DCA Strategy Category --> Determines DoE_PARAM DICT\n",
    "DoE_PARAM = {\"le_strategy\":\"leV1\", \"random_seed\":2,\"start\":0,\"stop\":90,\"step\":7,\"p_vec\":None}    #stop = max 90% of test_set_size, step=1-10 \n",
    "EXP_FOLD = \"simulation_results/\"                            #respect folder structure\n",
    "SAVE_FILES = True \n",
    "DATA_VIS  = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier MR-Hydra, Dataset Beef 100%\n",
    "current_ds, current_meta = dataset_provider(name=DATASET_NAME, reduction_factor=REDUCTION_F, test_set_ratio=\"default_benchmark\", random_state=0)\n",
    "#x_t, y_t = dataset_overview(train_test_dct=current_ds[\"y_train_small\"] , dataset_name=DATASET_NAME)\n",
    "current_cl = _set_bakeoff_classifier(CLASSIFIER_NAME, random_state=0, n_jobs=1)\n",
    "cl_dict = {CLASSIFIER_NAME: current_cl}\n",
    "df_, trace_M_= apply_label_errors(train_test_df=current_ds, cl_dict=cl_dict, ds_=DATASET_NAME,doe_param=DoE_PARAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df_[\"y_pred\"].apply(type).value_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_ = current_ds[\"y_test_small\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_y_hist = np.array(df_.iloc[-1][\"y_train_history\"])\n",
    "last_y_pred = np.array(df_.iloc[-1][\"y_pred\"])\n",
    "\n",
    "y_test_ == last_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"ElectricDevices\"                   #should be in DS_list\n",
    "CLASSIFIER_NAME = \"Quant\"            #should be in cl_ names\n",
    "REDUCTION_F = 10                         #optional. only for large datasets\n",
    "RANDOM_S = 0                            #Random Seed for everything except the DCA\n",
    "DCA= \"LabelErrors\"                      #DCA Strategy Category --> Determines DoE_PARAM DICT\n",
    "DoE_PARAM = {\"le_strategy\":\"leV1\", \"random_seed\":0,\"start\":0,\"stop\":10,\"step\":1,\"p_vec\":None}    #stop = max 90% of test_set_size, step=1-10 \n",
    "EXP_FOLD = \"simulation_results/\"                            #respect folder structure\n",
    "SAVE_FILES = True \n",
    "DATA_VIS  = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_history_df(load_path):\n",
    "    with open(os.path.join(load_path, \"metrics.json\"), \"r\") as f:\n",
    "        metrics = json.load(f)\n",
    "\n",
    "    y_train_history = np.load(os.path.join(load_path, \"y_train_history.npy\"), allow_pickle=True)\n",
    "    y_pred = np.load(os.path.join(load_path, \"y_pred.npy\"), allow_pickle=True)\n",
    "    y_pred_prob = np.load(os.path.join(load_path, \"y_pred_prob.npy\"), allow_pickle=True)\n",
    "\n",
    "    # Reconstruct DataFrame\n",
    "    df = pd.DataFrame(metrics)\n",
    "    # df[\"y_train_history\"] = list(y_train_history)\n",
    "    # df[\"y_pred\"] = list(y_pred)\n",
    "    # df[\"y_pred_prob\"] = list(y_pred_prob)\n",
    "\n",
    "    #df[\"y_train_history\"] = df[\"y_train_history\"].apply(lambda x: [str(i) for i in x])\n",
    "    #df[\"y_pred\"] = df[\"y_pred\"].apply(lambda x: [str(i) for i in x])\n",
    "\n",
    "    df[\"y_train_history\"] = [np.array(x, dtype=str) for x in y_train_history]\n",
    "    df[\"y_pred\"] = [np.array(x, dtype=str) for x in y_pred]\n",
    "    df[\"y_pred_prob\"] = list(y_pred_prob)  # unchanged\n",
    "\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = load_history_df(\"simulation_results/Quant/ElectricDevices/leV1_0_0_180_9\")\n",
    "\n",
    "y_train_9 = history_df.loc[1,\"y_train_history\"]\n",
    "y_train_0 = history_df.loc[0,\"y_train_history\"]\n",
    "\n",
    "y_train_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-07 11:25:50] INFO - requested_instance_step = 8.92 will be transformed into 9\n",
      "[2025-05-07 11:25:50] INFO - label_names: ['1' '2' '3' '4' '5' '6' '7']\n",
      "[2025-05-07 11:25:50] INFO - Current Label Error Strategy: DEFAULT: leV1\n",
      "[2025-05-07 11:25:50] INFO - The p_vector for the current_experiment: [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429]\n",
      "[2025-05-07 11:25:50] INFO - Searching inside simulation_results/Quant/ElectricDevices for results\n",
      "[2025-05-07 11:25:50] INFO - üìÅ Found directories: ['leV1_1_0_810_45', 'leV1_0_0_810_45', 'leV1_0_0_90_9']\n",
      "[2025-05-07 11:25:50] INFO - üü° Coarse Match found: leV1_0_0_810_45\n",
      "[2025-05-07 11:25:50] INFO - ‚úÖ Exact match found: leV1_0_0_90_9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train             : (8926, 1, 96)\n",
      "y_train             : (8926,)\n",
      "X_test              : (7711, 1, 96)\n",
      "y_test              : (7711,)\n",
      "X_train_small       : (892, 1, 96)\n",
      "y_train_small       : (892,)\n",
      "X_test_small        : (771, 1, 96)\n",
      "y_test_small        : (771,)\n"
     ]
    }
   ],
   "source": [
    "# Classifier Quant, Dataset ED 10%\n",
    "current_ds, current_meta = dataset_provider(name=DATASET_NAME, reduction_factor=REDUCTION_F, test_set_ratio=\"default_benchmark\", random_state=0)\n",
    "#x_t, y_t = dataset_overview(train_test_dct=current_ds[\"y_train_small\"] , dataset_name=DATASET_NAME)\n",
    "current_cl = _set_bakeoff_classifier(CLASSIFIER_NAME, random_state=0, n_jobs=1)\n",
    "cl_dict = {CLASSIFIER_NAME: current_cl}\n",
    "df_, trace_M_= apply_label_errors(train_test_df=current_ds, cl_dict=cl_dict, ds_=DATASET_NAME, doe_param=DoE_PARAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier Quant, Dataset ED\n",
    "ds_ED, meta_ED = dataset_provider(name=\"ElectricDevices\", reduction_factor=10, test_set_ratio=\"default_benchmark\", random_state=0)\n",
    "x_t, y_t = dataset_overview(train_test_dct=ds_ED[\"y_train_small\"] , dataset_name=\"ElectricDevices0\")\n",
    "QUANT= _set_bakeoff_classifier(\"quant\", random_state=0, n_jobs=1)\n",
    "cl_dict = {\"QUANT\":QUANT}\n",
    "DoE_PARAM = {\"le_strategy\":\"leV1\", \"random_seed\":0,\"start\":0,\"stop\":26,\"step\":1,\"p_vec\":None}\n",
    "df_, trace_M_= apply_label_errors(train_test_df=current_ds, cl_dict=cl_dict, ds_=DATASET_NAME,doe_param=DoE_PARAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier Quant, Dataset ED\n",
    "ds_ED, meta_ED = dataset_provider(name=\"ElectricDevices\", reduction_factor=10, test_set_ratio=\"default_benchmark\", random_state=0)\n",
    "x_t, y_t = dataset_overview(train_test_dct=ds_ED[\"y_train_small\"] , dataset_name=\"ElectricDevices0\")\n",
    "QUANT= _set_bakeoff_classifier(\"quant\", random_state=0, n_jobs=1)\n",
    "cl_dict = {\"QUANT\":QUANT}\n",
    "df_ED_QUANT, trace_m_ED_QUANT = apply_label_errors(train_test_df=ds_ED, cl_dict=cl_dict, ds_=\"ElectricDevices\",\n",
    "                                                    stop=400, step=5, stop_percentage=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_acc_decr(df_acc_inst_rel=df_ED_QUANT, dpi_=150, first=\"relative\", second=None, w_=4.5, h_=3,\n",
    "                   cl_=\"QUANT\", ds_=\"ElectricDevices\", save_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_trace_M(trace_M=trace_m_ED_QUANT, cl_=\"Quant\", ds_=\"ED\",dpi=200, filename_=\"trace_M\", save_fig=False, exp_folder=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classifier Weasel-D, Dataset ED\n",
    "ds_ED, meta_ED = dataset_provider(name=\"ElectricDevices\", reduction_factor=10, test_set_ratio=\"default_benchmark\", random_state=0)\n",
    "x_t, y_t = dataset_overview(train_test_dct=ds_ED[\"y_train_small\"] , dataset_name=\"ElectricDevices0\")\n",
    "Weasel_D= _set_bakeoff_classifier(\"Weasel-D\", random_state=0, n_jobs=1)\n",
    "cl_dict = {\"Weasel-D\":Weasel_D}\n",
    "df_ED_W2, trace_m_ED_W2 = apply_label_errors(train_test_df=ds_ED, cl_dict=cl_dict, ds_=\"ElectricDevices\",\n",
    "                                                                stop=400, step=5, stop_percentage=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_acc_decr(df_acc_inst_rel=df_ED_W2, dpi_=150, first=\"relative\", second=None, w_=4.5, h_=3,\n",
    "                   cl_=\"WEASEL-D\", ds_=\"ElectricDevices\", save_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier Weasel-D, Dataset LKA\n",
    "ds_LKA, meta_LKA = dataset_provider(name=\"LargeKitchenAppliances\", reduction_factor=1, test_set_ratio=\"default_benchmark\", random_state=0)\n",
    "x_t, y_t = dataset_overview(train_test_dct=ds_LKA[\"y_train_small\"] , dataset_name=\"LargeKitchenAppliances0\")\n",
    "Weasel_D = _set_bakeoff_classifier(\"Weasel-D\", random_state=0, n_jobs=1)\n",
    "cl_dict2 = {\"Weasel-D\": Weasel_D}\n",
    "df_LKA_W2, res_LKA_W2, trace_m_LKA_W2 = apply_label_errors(train_test_df=ds_LKA, cl_dict=cl_dict2, ds_=\"LKA\", stop=180, stop_percentage=0.7,  step=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_acc_decr(df_acc_inst_rel=df_LKA_W2, dpi_=150, first=\"relative\", second=None, w_=4.5, h_=3,\n",
    "                   cl_=\"Weasel-D\", ds_=\"LargeKitchenApplications\", save_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_trace_M(trace_M=trace_m_LKA_W2, cl_=\"Weasel-D\", ds_=\"LKA\",dpi=200, filename_=\"trace_M\", save_fig=False, exp_folder=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
